<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Look Around">
  <meta name="keywords" content="Embodied learning, Object detection, Reinforcement learning, Finetuning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>Look Around and Learn: Self-Improving Object Detection by Exploration</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <!-- <link rel="stylesheet" href="./static/css/bulma-carousel.min.css"> -->
  <!-- <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script> -->
  <!-- <script src="./static/js/bulma-slider.min.js"></script> -->
  <script src="./static/js/index.js"></script>
</head>


<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Look Around and Learn: Self-Improving Object Detection by Exploration</h1>
          <h2 class="title is-6 publication-title">ECCV 2024</h2>
          <div class="is-size-6 publication-authors">
            <span class="author-block">
              <a href="">Gianluca Scarpellini</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="stefanorosa.it">Stefano Rosa</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Pietro Morerio</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Lorenzo Natale</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Alessio Del Bue</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>Istituto Italiano di Tecnologia, Genoa, Italy</span>
          </div>

          <div class="is-size-6 publication-authors">
            <span  class="author-block"><sup>2</sup>University of Genoa, Genoa, Italy</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07259.pdf"
                   class="external-link button is-normal ">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/1Dc5pfdwHms"
                   class="external-link button is-normal ">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/IIT-PAVIS/Look_Around_And_Learn"
                   class="external-link button is-normal ">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal" disabled="true">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%"> -->
        <img source src="./static/images/splash.gif" />
      <!-- </video> -->
      <h2 class="subtitle has-text-centered">
        We equip an agent with an off-the-shelf MaskRCNN detector. The agent explores new environments and collects a set of noisy detections using a learned exploration policy. Such detections are then used for finetuning the detector.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/1Dc5pfdwHms" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Object detectors often experience a drop in performance when new environmental conditions are insufficiently represented in the training data. This paper studies how to automatically fine-tune a preexisting object detector while exploring and acquiring images in a new environment without relying on human intervention, i.e., in an utterly self-supervised fashion. In our setting, an agent initially learns to explore the environment using a pre-trained off-the-shelf detector to locate objects and associate pseudo-labels. By assuming that pseudo-labels for the same object must be consistent across different views, we learn an exploration policy mining hard samples and we devise a novel mechanism for
            producing refined predictions from the consensus among observations.
            Our approach outperforms the current state-of-the-art, and it closes the performance gap against a fully supervised setting without relying on ground-truth annotations. We also compare various exploration policies for the agent to gather more informative observations.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Approach</h2>

      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Action loop</h2>
          <div class="interpolation-image-wrapper-zero-shot">
            <img src="./static/images/fig2_iros.jpg"  width="75%" height="75%"/>
          </div>
            <p>Our policy predicts long-term goals for the agent. The agent builds a semantically consistent voxel map of the environment by projecting detected objects into a 3D voxel-map. The voxel-map is down-projected onto a top-down view and a disagreement map is computed by assigning a disagreement score value to each cell based on one of two measures.The disagreement map is the input of the policy network. The policy is trained to predict the goal that maximizes the total disagreement. </p>
        </div>
      </div>

      <div class="column">
        <h2 class="title is-4">Reprojecting detections onto 2D frames</h2>
        <div class="columns is-centered">
          <div class="column content">
            <div class="Reprojecting">
              <img src="./static/images/reprojection.jpg" />
            </div>
              <p>During exploration, detections are aggregated into the semantic voxel-map. Inconsistencies in the voxel-map are solved by assigning to each voxel the class with the maximum score among the predictions belonging to the voxel. 
              Then, the semantic voxel-map is reprojected onto each observation, obtaining a set of consistent pseudo-labels. Each pseudo-label is associated to an object instance via a unique identifier and contains a consistent logits vector.</p>
          </div>
        </div>

        <div class="content">
          <h2 class="title is-4">Instance-matching loss</h2>
              <div class="Instance">
                <img src="./static/images/triplet.jpg" />
              </div>
                <p>The instance-matching loss exploits disagreements between predictions for the same object. In fact, it enforces feature vectors belonging to the same object to be close in the feature space, while enforcing feature vectors of different objects to be farther away.</p>
        </div>
      </div>
    </div>
  </div>
</section>


<script type="text/javascript">
  $(function() {
  var screenWidth = $(window).width();
  if (screenWidth >= 800) {
    $('#gpt-video-1').attr('autoplay', 'autoplay');
  }
  if (screenWidth >= 800) {
    $('#gpt-video-2').attr('autoplay', 'autoplay');
  }
  if (screenWidth >= 800) {
    $('#click-query-icl').attr('autoplay', 'autoplay');
  }
});
</script>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{lookaround2024,
      title={Look around and learn: self-improving object detection by exploration}, 
      author={Gianluca Scarpellini and Stefano Rosa and Pietro Morerio and Lorenzo Natale and Alessio Del Bue},
      year={2024},
      eprint={2302.03566},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      booktitle={European Conference on Computer Vision},
      }

    </code>
    </pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
        <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website adapted from the Nerfies templates, which is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the source code of this website,
            we just ask that you link back to the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies source code</a> in the footer.
            Please remember to remove the analytics code included in the header of the website which you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
